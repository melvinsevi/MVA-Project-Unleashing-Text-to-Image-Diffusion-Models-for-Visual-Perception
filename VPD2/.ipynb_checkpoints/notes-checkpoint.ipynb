{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43233028-3cce-4252-bfff-b8dee07b7faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unzip\n",
      "  Downloading unzip-1.0.0.tar.gz (704 bytes)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: unzip\n",
      "  Building wheel for unzip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for unzip: filename=unzip-1.0.0-py3-none-any.whl size=1281 sha256=4ab143c8bac9a7603b4fa5128a6a22ee5bc7b65e42f3871657f6b8ed73e340a2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/80/dc/7a/f8af45bc239e7933509183f038ea8d46f3610aab82b35369f4\n",
      "Successfully built unzip\n",
      "Installing collected packages: unzip\n",
      "Successfully installed unzip-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8650bae5-20be-43cc-9dfd-4ad8ac02f6c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb  VPD2.zip\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a00dd6f-e7dc-4fa7-bc0f-9d60ac5e3ada",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  VPD2.zip\n",
      "   creating: VPD++/VPD/\n",
      "   creating: VPD++/VPD/checkpoints/\n",
      "   creating: VPD++/VPD/refer/\n",
      "  inflating: VPD++/VPD/refer/args.py  \n",
      "   creating: VPD++/VPD/refer/data/\n",
      "  inflating: VPD++/VPD/refer/data/dataset_refer_clip.py  \n",
      "   creating: VPD++/VPD/refer/data/images/\n",
      "   creating: VPD++/VPD/refer/data/images/mscoco/\n",
      "   creating: VPD++/VPD/refer/data/images/mscoco/images/\n",
      "   creating: VPD++/VPD/refer/data/images/mscoco/images/train2014/\n",
      "   creating: VPD++/VPD/refer/data/refclef/\n",
      "   creating: VPD++/VPD/refer/data/refclef/.ipynb_checkpoints/\n",
      "  inflating: VPD++/VPD/refer/data/refclef/instances.json  \n",
      "  inflating: VPD++/VPD/refer/data/refclef/refs(berkeley).p  \n",
      "  inflating: VPD++/VPD/refer/data/refclef/refs(unc).p  \n",
      "   creating: VPD++/VPD/refer/data/refcoco/\n",
      "  inflating: VPD++/VPD/refer/data/refcoco/instances.json  \n",
      "  inflating: VPD++/VPD/refer/data/refcoco/refs(google).p  \n",
      "  inflating: VPD++/VPD/refer/data/refcoco/refs(unc).p  \n",
      "   creating: VPD++/VPD/refer/data/refcoco+/\n",
      "  inflating: VPD++/VPD/refer/data/refcoco+/instances.json  \n",
      "  inflating: VPD++/VPD/refer/data/refcoco+/refs(unc).p  \n",
      "   creating: VPD++/VPD/refer/data/refcocog/\n",
      "   creating: VPD++/VPD/refer/data/refcocog/.ipynb_checkpoints/\n",
      "  inflating: VPD++/VPD/refer/data/refcocog/instances.json  \n",
      "  inflating: VPD++/VPD/refer/data/refcocog/refs(google).p  \n",
      "  inflating: VPD++/VPD/refer/data/refcocog/refs(umd).p  \n",
      "   creating: VPD++/VPD/refer/lib/\n",
      "   creating: VPD++/VPD/refer/lib/.ipynb_checkpoints/\n",
      "  inflating: VPD++/VPD/refer/lib/.ipynb_checkpoints/mask_predictor-checkpoint.py  \n",
      "   creating: VPD++/VPD/refer/lib/__pycache__/\n",
      "  inflating: VPD++/VPD/refer/lib/__pycache__/mask_predictor.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/refer/lib/mask_predictor.py  \n",
      "   creating: VPD++/VPD/refer/models_refer/\n",
      "   creating: VPD++/VPD/refer/models_refer/.ipynb_checkpoints/\n",
      "  inflating: VPD++/VPD/refer/models_refer/.ipynb_checkpoints/model-checkpoint.py  \n",
      " extracting: VPD++/VPD/refer/models_refer/__init__.py  \n",
      "   creating: VPD++/VPD/refer/models_refer/__pycache__/\n",
      "  inflating: VPD++/VPD/refer/models_refer/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/refer/models_refer/__pycache__/model.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/refer/models_refer/model.py  \n",
      "  inflating: VPD++/VPD/refer/my_test.py  \n",
      "  inflating: VPD++/VPD/refer/my_train (1).py  \n",
      "  inflating: VPD++/VPD/refer/Notebook.ipynb  \n",
      "  inflating: VPD++/VPD/refer/README.md  \n",
      "   creating: VPD++/VPD/refer/refer/\n",
      "   creating: VPD++/VPD/refer/refer/.ipynb_checkpoints/\n",
      "  inflating: VPD++/VPD/refer/refer/.ipynb_checkpoints/refer-checkpoint.py  \n",
      "   creating: VPD++/VPD/refer/refer/__pycache__/\n",
      "  inflating: VPD++/VPD/refer/refer/__pycache__/refer.cpython-310.pyc  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/\n",
      "   creating: VPD++/VPD/refer/refer/evaluation/.ipynb_checkpoints/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/__init__.py  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/bleu/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/bleu/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/bleu/bleu.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/bleu/bleu_scorer.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/bleu/LICENSE  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/cider/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/cider/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/cider/cider.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/cider/cider_scorer.py  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/meteor/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/meteor/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/meteor/meteor.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/readme.txt  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/refEvaluation.py  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/rouge/\n",
      "   creating: VPD++/VPD/refer/refer/evaluation/rouge/.ipynb_checkpoints/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/rouge/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/rouge/rouge.py  \n",
      "   creating: VPD++/VPD/refer/refer/evaluation/tokenizer/\n",
      " extracting: VPD++/VPD/refer/refer/evaluation/tokenizer/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/tokenizer/ptbtokenizer.py  \n",
      "  inflating: VPD++/VPD/refer/refer/evaluation/tokenizer/stanford-corenlp-3.4.1.jar  \n",
      "   creating: VPD++/VPD/refer/refer/external/\n",
      " extracting: VPD++/VPD/refer/refer/external/__init__.py  \n",
      "  inflating: VPD++/VPD/refer/refer/external/_mask.pyx  \n",
      "  inflating: VPD++/VPD/refer/refer/external/mask.py  \n",
      "  inflating: VPD++/VPD/refer/refer/external/maskApi.c  \n",
      "  inflating: VPD++/VPD/refer/refer/external/maskApi.h  \n",
      "  inflating: VPD++/VPD/refer/refer/external/README.md  \n",
      "  inflating: VPD++/VPD/refer/refer/LICENSE  \n",
      "  inflating: VPD++/VPD/refer/refer/Makefile  \n",
      "  inflating: VPD++/VPD/refer/refer/my_test.py  \n",
      "  inflating: VPD++/VPD/refer/refer/pyEvalDemo.ipynb  \n",
      "  inflating: VPD++/VPD/refer/refer/pyReferDemo.ipynb  \n",
      "  inflating: VPD++/VPD/refer/refer/README.md  \n",
      "  inflating: VPD++/VPD/refer/refer/refer.py  \n",
      "  inflating: VPD++/VPD/refer/refer/setup.py  \n",
      "   creating: VPD++/VPD/refer/refer/test/\n",
      "  inflating: VPD++/VPD/refer/refer/test/sample_expressions_testA.json  \n",
      "  inflating: VPD++/VPD/refer/refer/test/sample_expressions_testB.json  \n",
      " extracting: VPD++/VPD/refer/refer/untitled  \n",
      "  inflating: VPD++/VPD/refer/requirements (2).txt  \n",
      "  inflating: VPD++/VPD/refer/test.py  \n",
      "  inflating: VPD++/VPD/refer/test.sh  \n",
      "  inflating: VPD++/VPD/refer/train.py  \n",
      "  inflating: VPD++/VPD/refer/train.sh  \n",
      "  inflating: VPD++/VPD/refer/transforms.py  \n",
      "  inflating: VPD++/VPD/refer/utils.py  \n",
      "  inflating: VPD++/VPD/refer/v1-inference.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/branches/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/config  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/description  \n",
      " extracting: VPD++/VPD/stablediffusion/.git/HEAD  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/hooks/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/applypatch-msg.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/commit-msg.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/fsmonitor-watchman.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/post-update.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-applypatch.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-commit.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-merge-commit.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/prepare-commit-msg.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-push.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-rebase.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/pre-receive.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/push-to-checkout.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/hooks/update.sample  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/index  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/info/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/info/exclude  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/logs/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/logs/HEAD  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/logs/refs/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/logs/refs/heads/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/logs/refs/heads/main  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/logs/refs/remotes/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/logs/refs/remotes/origin/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/logs/refs/remotes/origin/HEAD  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/objects/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/objects/info/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/objects/pack/\n",
      "  inflating: VPD++/VPD/stablediffusion/.git/objects/pack/pack-829a19fcf6c2a33a1beb5198c6c4e04b271b98e8.idx  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/objects/pack/pack-829a19fcf6c2a33a1beb5198c6c4e04b271b98e8.pack  \n",
      "  inflating: VPD++/VPD/stablediffusion/.git/packed-refs  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/refs/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/refs/heads/\n",
      " extracting: VPD++/VPD/stablediffusion/.git/refs/heads/main  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/refs/remotes/\n",
      "   creating: VPD++/VPD/stablediffusion/.git/refs/remotes/origin/\n",
      " extracting: VPD++/VPD/stablediffusion/.git/refs/remotes/origin/HEAD  \n",
      "   creating: VPD++/VPD/stablediffusion/.git/refs/tags/\n",
      "   creating: VPD++/VPD/stablediffusion/assets/\n",
      "  inflating: VPD++/VPD/stablediffusion/assets/a-painting-of-a-fire.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/a-photograph-of-a-fire.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/a-shirt-with-a-fire-printed-on-it.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/a-shirt-with-the-inscription-'fire'.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/a-watercolor-painting-of-a-fire.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/birdhouse.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/fire.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/inpainting.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/inpaintingbanner.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/modelfigure.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/rdm-preview.jpg  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/reconstruction1.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/reconstruction2.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/results.gif  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/rick.jpeg  \n",
      "   creating: VPD++/VPD/stablediffusion/assets/stable-inpainting/\n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-inpainting/merged-bench.png  \n",
      "   creating: VPD++/VPD/stablediffusion/assets/stable-samples/\n",
      "   creating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/\n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/mountains-1.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/mountains-2.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/mountains-3.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/sketch-mountains-input.jpg  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/upscaling-in.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/img2img/upscaling-out.png  \n",
      "   creating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/\n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/000002025.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/000002035.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/merged-0005.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/merged-0006.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/stable-samples/txt2img/merged-0007.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/the-earth-is-on-fire,-oil-on-canvas.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/txt2img-convsample.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/txt2img-preview.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/v1-1-to-v1-5.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/assets/v1-variants-scores.jpg  \n",
      "   creating: VPD++/VPD/stablediffusion/configs/\n",
      "   creating: VPD++/VPD/stablediffusion/configs/autoencoder/\n",
      "  inflating: VPD++/VPD/stablediffusion/configs/autoencoder/autoencoder_kl_16x16x16.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/autoencoder/autoencoder_kl_32x32x4.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/autoencoder/autoencoder_kl_64x64x3.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/autoencoder/autoencoder_kl_8x8x64.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/configs/latent-diffusion/\n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/celebahq-ldm-vq-4.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/cin256-v2.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/cin-ldm-vq-f8.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/ffhq-ldm-vq-4.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/lsun_bedrooms-ldm-vq-4.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/lsun_churches-ldm-kl-8.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/latent-diffusion/txt2img-1p4B-eval.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/configs/retrieval-augmented-diffusion/\n",
      "  inflating: VPD++/VPD/stablediffusion/configs/retrieval-augmented-diffusion/768x768.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/configs/stable-diffusion/\n",
      "  inflating: VPD++/VPD/stablediffusion/configs/stable-diffusion/v1-inference.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/configs/stable-diffusion/v1-inpainting-inference.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/data/\n",
      "  inflating: VPD++/VPD/stablediffusion/data/DejaVuSans.ttf  \n",
      "   creating: VPD++/VPD/stablediffusion/data/example_conditioning/\n",
      "   creating: VPD++/VPD/stablediffusion/data/example_conditioning/superresolution/\n",
      "  inflating: VPD++/VPD/stablediffusion/data/example_conditioning/superresolution/sample_0.jpg  \n",
      "   creating: VPD++/VPD/stablediffusion/data/example_conditioning/text_conditional/\n",
      " extracting: VPD++/VPD/stablediffusion/data/example_conditioning/text_conditional/sample_0.txt  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/imagenet_clsidx_to_label.txt  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/imagenet_train_hr_indices.p  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/imagenet_val_hr_indices.p  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/index_synset.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/data/inpainting_examples/\n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/6458524847_2f4c361183_k.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/6458524847_2f4c361183_k_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/8399166846_f6fb4e4b8e_k.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/8399166846_f6fb4e4b8e_k_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/alex-iby-G_Pk4D9rMLs.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/alex-iby-G_Pk4D9rMLs_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/bench2.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/bench2_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/bertrand-gabioud-CpuFzIsHYJ0.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/bertrand-gabioud-CpuFzIsHYJ0_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/billow926-12-Wc-Zgx6Y.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/billow926-12-Wc-Zgx6Y_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/photo-1583445095369-9c651e7e5d34.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/data/inpainting_examples/photo-1583445095369-9c651e7e5d34_mask.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/environment.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/\n",
      "   creating: VPD++/VPD/stablediffusion/ldm/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/__pycache__/util.cpython-310.pyc  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/data/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/data/__init__.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/data/base.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/data/imagenet.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/data/lsun.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/lr_scheduler.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/models/\n",
      "   creating: VPD++/VPD/stablediffusion/ldm/models/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/__pycache__/autoencoder.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/autoencoder.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/models/diffusion/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/models/diffusion/__init__.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/models/diffusion/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/__pycache__/ddim.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/__pycache__/ddpm.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/classifier.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/ddim.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/ddpm.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/models/diffusion/plms.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/\n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/__pycache__/attention.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/__pycache__/ema.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/__pycache__/x_transformer.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/attention.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__init__.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__pycache__/model.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__pycache__/openaimodel.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/__pycache__/util.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/model.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/openaimodel.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/diffusionmodules/util.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/distributions/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/modules/distributions/__init__.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/distributions/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/distributions/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/distributions/__pycache__/distributions.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/distributions/distributions.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/ema.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/encoders/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/modules/encoders/__init__.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/encoders/__pycache__/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/encoders/__pycache__/__init__.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/encoders/__pycache__/modules.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/encoders/modules.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/__init__.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/bsrgan.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/bsrgan_light.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/utils/\n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/utils/test.png  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/image_degradation/utils_image.py  \n",
      "   creating: VPD++/VPD/stablediffusion/ldm/modules/losses/\n",
      " extracting: VPD++/VPD/stablediffusion/ldm/modules/losses/__init__.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/losses/contperceptual.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/losses/vqperceptual.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/modules/x_transformer.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/ldm/util.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/LICENSE  \n",
      "  inflating: VPD++/VPD/stablediffusion/main.py  \n",
      "   creating: VPD++/VPD/stablediffusion/models/\n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/\n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f16/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f16/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f32/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f32/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f4/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f4/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f8/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/kl-f8/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f16/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f16/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f4/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f4/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f4-noattn/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f4-noattn/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f8/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f8/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f8-n256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/first_stage_models/vq-f8-n256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/\n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/bsr_sr/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/bsr_sr/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/celeba256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/celeba256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/cin256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/cin256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/ffhq256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/ffhq256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/inpainting_big/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/inpainting_big/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/layout2img-openimages256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/layout2img-openimages256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/lsun_beds256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/lsun_beds256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/lsun_churches256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/lsun_churches256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/semantic_synthesis256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/semantic_synthesis256/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/semantic_synthesis512/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/semantic_synthesis512/config.yaml  \n",
      "   creating: VPD++/VPD/stablediffusion/models/ldm/text2img256/\n",
      "  inflating: VPD++/VPD/stablediffusion/models/ldm/text2img256/config.yaml  \n",
      "  inflating: VPD++/VPD/stablediffusion/notebook_helpers.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/README.md  \n",
      "  inflating: VPD++/VPD/stablediffusion/requirements.txt  \n",
      "   creating: VPD++/VPD/stablediffusion/scripts/\n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/download_first_stages.sh  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/download_models.sh  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/img2img.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/inpaint.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/inpaint_st.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/knn2img.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/latent_imagenet_diffusion.ipynb  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/sample_diffusion.py  \n",
      "   creating: VPD++/VPD/stablediffusion/scripts/tests/\n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/tests/test_watermark.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/train_searcher.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/scripts/txt2img.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/setup.py  \n",
      "  inflating: VPD++/VPD/stablediffusion/Stable_Diffusion_v1_Model_Card.md  \n",
      "   creating: VPD++/VPD/tamingtransformers/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/branches/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/config  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/description  \n",
      " extracting: VPD++/VPD/tamingtransformers/.git/HEAD  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/hooks/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/applypatch-msg.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/commit-msg.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/fsmonitor-watchman.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/post-update.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-applypatch.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-commit.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-merge-commit.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/prepare-commit-msg.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-push.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-rebase.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/pre-receive.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/push-to-checkout.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/hooks/update.sample  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/index.lock  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/info/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/info/exclude  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/logs/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/logs/HEAD  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/logs/refs/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/logs/refs/heads/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/logs/refs/heads/master  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/logs/refs/remotes/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/logs/refs/remotes/origin/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/logs/refs/remotes/origin/HEAD  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/objects/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/objects/info/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/objects/pack/\n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/objects/pack/pack-34e24108d627c8d57cba87fd86552b8cca48134a.idx  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/objects/pack/pack-34e24108d627c8d57cba87fd86552b8cca48134a.pack  \n",
      "  inflating: VPD++/VPD/tamingtransformers/.git/packed-refs  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/refs/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/refs/heads/\n",
      " extracting: VPD++/VPD/tamingtransformers/.git/refs/heads/master  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/refs/remotes/\n",
      "   creating: VPD++/VPD/tamingtransformers/.git/refs/remotes/origin/\n",
      " extracting: VPD++/VPD/tamingtransformers/.git/refs/remotes/origin/HEAD  \n",
      "   creating: VPD++/VPD/tamingtransformers/.git/refs/tags/\n",
      "   creating: VPD++/VPD/tamingtransformers/assets/\n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/birddrawnbyachild.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/coco_scene_images_training.svg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/drin.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/faceshq.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/first_stage_mushrooms.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/first_stage_squirrels.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/imagenet.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/lake_in_the_mountains.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/mountain.jpeg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/scene_images_samples.svg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/stormy.jpeg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/sunset_and_ocean.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/assets/teaser.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/configs/\n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/coco_cond_stage.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/coco_scene_images_transformer.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/custom_vqgan.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/drin_transformer.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/faceshq_transformer.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/faceshq_vqgan.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/imagenet_vqgan.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/imagenetdepth_vqgan.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/open_images_scene_images_transformer.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/configs/sflckr_cond_stage.yaml  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_examples.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/ade20k_images/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000123.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000125.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000126.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000203.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000262.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000287.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000289.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000303.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000509.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000532.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000573.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000603.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000636.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000734.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000875.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00000880.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001177.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001200.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001209.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001388.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001412.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001498.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001578.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001583.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001698.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001766.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001845.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001851.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001947.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_images/ADE_val_00001966.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000123.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000125.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000126.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000203.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000262.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000287.png  \n",
      " extracting: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000289.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000303.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000509.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000532.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000573.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000603.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000636.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000734.png  \n",
      " extracting: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000875.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00000880.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001177.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001200.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001209.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001388.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001412.png  \n",
      " extracting: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001498.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001578.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001583.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001698.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001766.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001845.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001851.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001947.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ade20k_segmentations/ADE_val_00001966.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/celebahqtrain.txt  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/celebahqvalidation.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/\n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/annotations/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/annotations/instances_train2017.json  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/annotations/instances_val2017.json  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/annotations/stuff_train2017.json  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/annotations/stuff_val2017.json  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010005.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010008.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010012.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010014.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010015.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010023.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010024.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010037.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010039.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010040.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010041.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010046.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010056.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010058.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010069.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010073.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010077.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010082.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010083.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010084.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010094.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010097.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010104.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010107.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010108.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010114.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010115.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010123.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010125.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010130.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010136.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010138.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010142.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010145.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010149.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010161.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010166.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010175.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010176.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010179.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010192.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010196.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010205.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010211.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010216.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010217.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010219.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010222.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010229.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010230.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010232.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010239.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010241.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010243.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010244.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010245.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010248.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010249.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010256.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010263.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010265.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010275.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010276.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010281.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010290.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010303.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010309.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010313.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010318.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010319.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010321.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010324.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010327.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010337.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010342.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010343.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010346.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010358.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010369.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010386.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010388.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010393.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010395.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010400.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010403.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010405.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010407.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010414.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010420.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010421.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010428.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010430.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010432.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010434.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010440.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010442.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010444.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010445.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010449.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/train2017/000000010463.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010092.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010363.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010583.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010707.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010764.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010977.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000010995.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011051.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011122.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011149.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011197.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011511.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011615.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011699.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011760.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000011813.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012062.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012120.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012280.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012576.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012639.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012667.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012670.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000012748.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013004.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013177.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013201.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013291.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013348.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013546.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013597.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013659.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013729.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013774.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000013923.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014007.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014038.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014226.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014380.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014439.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014473.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014831.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000014888.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015079.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015254.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015272.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015278.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015335.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015338.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015440.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015497.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015517.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015597.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015660.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015746.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015751.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000015956.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016010.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016228.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016249.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016439.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016451.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016502.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016598.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000016958.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017029.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017031.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017115.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017178.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017182.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017207.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017379.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017436.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017627.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017714.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017899.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017905.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000017959.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018150.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018193.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018380.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018491.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018519.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018575.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018737.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018770.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018833.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000018837.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019042.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019109.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019221.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019402.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019432.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019742.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019786.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000019924.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000020059.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000020107.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000020247.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_annotations_100/val2017/000000020333.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_examples.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_images/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000018380.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000052507.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000057672.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000064898.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000098392.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000110638.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000119445.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000128658.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000154358.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000166259.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000166563.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000175387.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000185599.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000205834.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000231169.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000237928.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000255824.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000256775.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000299355.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000299720.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000303653.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000323895.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000335529.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000348045.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000348481.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000350405.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000356347.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000361180.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000403385.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000406997.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000452122.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000491464.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000517069.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000522393.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_images/000000569273.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/coco_segmentations/\n",
      " extracting: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000018380.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000052507.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000057672.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000064898.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000098392.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000110638.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000119445.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000128658.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000154358.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000166259.png  \n",
      " extracting: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000166563.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000175387.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000185599.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000205834.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000231169.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000237928.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000255824.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000256775.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000299355.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000299720.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000303653.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000323895.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000335529.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000348045.png  \n",
      " extracting: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000348481.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000350405.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000356347.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000361180.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000403385.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000406997.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000452122.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000491464.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000517069.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000522393.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/coco_segmentations/000000569273.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/\n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01795545/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01795545/ILSVRC2012_val_00023344.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01819313/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01819313/ILSVRC2012_val_00003068.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01820546/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01820546/ILSVRC2012_val_00034784.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01820546/ILSVRC2012_val_00047491.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01828970/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01828970/ILSVRC2012_val_00001336.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01828970/ILSVRC2012_val_00008236.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01828970/ILSVRC2012_val_00046802.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01843065/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01843065/ILSVRC2012_val_00022439.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n01847000/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n01847000/ILSVRC2012_val_00022364.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02085782/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02085782/ILSVRC2012_val_00012298.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02086646/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02086646/ILSVRC2012_val_00011473.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02088466/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02088466/ILSVRC2012_val_00013651.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02089973/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02089973/ILSVRC2012_val_00000028.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02093256/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02093256/ILSVRC2012_val_00046547.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02096294/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02096294/ILSVRC2012_val_00042133.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02099601/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02099601/ILSVRC2012_val_00005697.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02099712/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02099712/ILSVRC2012_val_00023471.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02100877/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02100877/ILSVRC2012_val_00039863.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02101006/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02101006/ILSVRC2012_val_00032333.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02101006/ILSVRC2012_val_00047325.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02101556/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02101556/ILSVRC2012_val_00030540.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02102318/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02102318/ILSVRC2012_val_00024691.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02105505/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02105505/ILSVRC2012_val_00031252.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02110627/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02110627/ILSVRC2012_val_00008310.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_depth/n02111889/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_depth/n02111889/ILSVRC2012_val_00042625.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_examples.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/\n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01795545/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01795545/ILSVRC2012_val_00023344.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01819313/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01819313/ILSVRC2012_val_00003068.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01820546/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01820546/ILSVRC2012_val_00034784.JPEG  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01820546/ILSVRC2012_val_00047491.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01828970/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01828970/ILSVRC2012_val_00001336.JPEG  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01828970/ILSVRC2012_val_00008236.JPEG  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01828970/ILSVRC2012_val_00046802.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01843065/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01843065/ILSVRC2012_val_00022439.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n01847000/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n01847000/ILSVRC2012_val_00022364.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02085782/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02085782/ILSVRC2012_val_00012298.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02086646/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02086646/ILSVRC2012_val_00011473.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02088466/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02088466/ILSVRC2012_val_00013651.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02089973/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02089973/ILSVRC2012_val_00000028.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02093256/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02093256/ILSVRC2012_val_00046547.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02096294/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02096294/ILSVRC2012_val_00042133.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02099601/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02099601/ILSVRC2012_val_00005697.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02099712/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02099712/ILSVRC2012_val_00023471.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02100877/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02100877/ILSVRC2012_val_00039863.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02101006/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02101006/ILSVRC2012_val_00032333.JPEG  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02101006/ILSVRC2012_val_00047325.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02101556/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02101556/ILSVRC2012_val_00030540.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02102318/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02102318/ILSVRC2012_val_00024691.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02105505/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02105505/ILSVRC2012_val_00031252.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02110627/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02110627/ILSVRC2012_val_00008310.JPEG  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/drin_images/n02111889/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/drin_images/n02111889/ILSVRC2012_val_00042625.JPEG  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ffhqtrain.txt  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/ffhqvalidation.txt  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/flickr_tags.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/class-descriptions-boxable.csv  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/oidv6-train-annotations-bbox.csv  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ab31e6be35fed.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ab7bec71cc50a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ab8c20b3e5b58.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000abc075d659122.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000abc821f66a892.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000abe5eddc5b303.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ac34008b0ba4c.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ac8c676b6077a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ac95750ac7399.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000acf666d991c39.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ad0ecfb21ee63.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ad20b5e452b24.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ad3d42653f5f6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ad6c520be9ec5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ad6fa67b5ad96.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000adcdd7244ce4a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000adef7197e3118.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000adfe5b817011c.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ae235808cc1e8.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ae28755d2d20e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000aecd78b230135.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000aee0af66d4237.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000af180a3163f17.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000af631fb329557.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000afe7726e121ea.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b06c0eed42a4c.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b093da01e5bfe.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b09d5d3fc821f.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b0f235dcf2caa.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b0f5159f54105.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b168e791f591d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b1971d8daaeef.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b1b3b85edd850.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b1b92f0800e94.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b21663becc68e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b260e1f08a32a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b29496f75c8e5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b299b5f5ed902.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b2a982a903d0d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b2b00065e564a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b2d1789d5f80d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b38d9f2f664fe.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b393437134262.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b3940e7d25c03.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b397382b2464a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b42cae15622e0.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b432ae644b679.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b4671075914cd.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b485cedacbf97.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b4935979bf4b5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b4fcdf1af3361.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b50bdd1933a36.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b55559b0244d7.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b55e339f0b131.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b567c26dd4e5d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b59a7822679e6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b5bc07c0c5df7.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b606e130bdf5e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b63a1445f53c8.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b65a36ad46f9e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b70a84aab664b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b72e1446f8849.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b76a9b80ba43a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b7dfaa1810a83.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b81b5757963e0.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b825dea3016eb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b87119cc301cf.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b8d80f7386698.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9007a01f7405.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b93644609911f.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9814a07fd974.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9a97776b3634.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9b00d7aef8f5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9b61afea2cd4.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9c365c9e307a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9d6c0f7d794d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000b9f3ba4891c11.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ba221f70676c6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ba28d70b1a999.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ba3ca8a2ca955.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ba40bf7a2b458.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000ba940f8cfc9bf.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000baa6f7dae9b79.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bab5b1a67844e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb0ae453283b0.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb200fc78fc30.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb2f7132013dc.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb81adefe7332.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb846e2629e83.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bb8bd9b1bca65.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bbdf0dc8099d8.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc1eb7f74adae.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc33717a6371f.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc387c731dd97.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc5006eb7fd98.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc5ad4cc3ae73.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc75d38907c78.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bc7b0a1889bcb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bcd3bcd95cbb3.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train/000bcee5bed5446b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/train-images-boxable.csv  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c5b4d6bc25788d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c67960e389e4df.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c6ddd2c210450e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c7f89055cf399b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c863d76bcf6b00.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09c993afacd01547.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09cbba9f5e097a19.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09d2112596d9155b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09d354dbd3dcc857.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09d45c49c4adbae4.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09d64f43c7111879.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09d8aa2d19ff724d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09dcb9b52055d40f.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09dd0671cd633432.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09df63bd01367ca3.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09e094375efab7fe.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09e617d9d3120b32.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09ea349ee555b61d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09ebcee57699eb98.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09f531fe4f6d95f3.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09f8b77a88f224d9.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09f8e760f60df0da.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/09fa093bcd300c1a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a02c648d24f39fb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a02e8b6820064f5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a03326036647703.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a08a4711c728078.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a120822d362dddf.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a13dcaaab9a35e0.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a1b11867383b13e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a1bd356f90aaab6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a1f4761dc7fe1eb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a23d3f0e7d850f4.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a278d979b63fc72.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a2c6ef66896fb92.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a34d80ee1db201e.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a37aa0734ac8016.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a3873442ad329c2.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a392d80c905a9df.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a39325e5ad7f5a0.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a3c01759e77a02d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a3f577a327ca7cc.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a3f9b3d57ef354a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a41cda5f44baaf6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a47e7d602855f93.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a4abf0a8071b917.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a4db5693da70448.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a50911d08250183.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a556c8163b58fae.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a563d05ebab4fe3.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a5972c68b6bb265.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a599940d33b6b2b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a600f1148d1023c.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a6a03c8f23ee744.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a6bc386b28f2aac.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7074a2a5515531.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a72fef43a51c479.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a73064c82730ff5.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a78374f2d3949ae.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7be0b883a12966.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7c597abf1e90d4.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7d56b2fb989fe8.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7f13330a5d0023.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7f4d9a0ccb9afe.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7fbc1d68e4e5ae.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a7ffd65766a4741.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a82f0443c940816.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a8657e8b5c9d7bb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a877314ca2039d9.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a917bbca24cf75d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a94296ff543a1dc.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a9f183e46c76019.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a9f73b3c2557150.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0a9ff75a7897e757.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aa206fa7ea80036.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aa3a6c33fca122b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aaad833ac61ac9d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aacbdb54e853a0a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aad9fc79a35bd53.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0aae34863935e33a.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ab050b51e78acdb.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ab10a6417ef2301.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ab2b64f27f8baca.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ab5c690eebfad95.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ac166d12e401a98.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ac2f91a7995aa8b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ac3c1db1b3645f2.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ac51477636a6933.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ac52440f73b5c80.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0acfa779589204bf.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ad602c943c9f568.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ad7884032419621.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ad7bad30cd432df.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ad96a2881998657.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ad99d610a9092e6.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ada35baba28134b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0adc1330287b2e66.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0adc373e996aadc2.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0add91a2efb3f33d.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation/0ade7aef439e2102.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation-annotations-bbox.csv  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/open_images_annotations_100/validation-images.csv  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_examples.txt  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/\n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/alaska_lakes/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/alaska_lakes/43259216952_59352d7204_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/australia/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/australia/12822389285_a7723081b5_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/australia/8720651218_ca82a6608e_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/black_forest/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/black_forest/44974691685_8e7372e2b1_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/black_forest/8364557382_c6c9ee2fd6_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/canada/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/canada/256743165_9f130ba95b_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/canada/2883773_881c197107_c.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/carribean/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/carribean/14351041152_ef77484a1f_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/carribean/18176301_c9d27557cf_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/cliff_ocean/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/cliff_ocean/36142796444_45d452f567_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/desert/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/desert/4534149722_3cc4f92891_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/geysir/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/geysir/14996762478_a9bdbf959a_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/geysir/26320755536_7c769b6218_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/geysir/3542389801_a2cbfee1e1_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/geysir/4748115806_7219c2b3be_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/ireland/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/ireland/15570753471_74db396d14_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/lakes/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/lakes/39933489595_f0e5d85b6d_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/meadow/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/meadow/18864473291_844325caab_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/mongolia/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/mongolia/6076373946_e9ea2aee32_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/newzealand_np/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/newzealand_np/7942812194_9348729b93_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/norway/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/norway/20099378793_cc2df820af_b.jpg  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/norway/25735082181_999927fe5a_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/swiss_landscape/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/swiss_landscape/4079319632_0133685b2c_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/swiss_mountains/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/swiss_mountains/33509672006_bf4c416afd_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_images/volcano/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_images/volcano/50254383883_27ed6ea93a_b.jpg  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/\n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/alaska_lakes/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/alaska_lakes/43259216952_59352d7204_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/australia/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/australia/12822389285_a7723081b5_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/australia/8720651218_ca82a6608e_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/black_forest/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/black_forest/44974691685_8e7372e2b1_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/black_forest/8364557382_c6c9ee2fd6_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/canada/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/canada/256743165_9f130ba95b_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/canada/2883773_881c197107_c.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/carribean/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/carribean/14351041152_ef77484a1f_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/carribean/18176301_c9d27557cf_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/cliff_ocean/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/cliff_ocean/36142796444_45d452f567_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/desert/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/desert/4534149722_3cc4f92891_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/geysir/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/geysir/14996762478_a9bdbf959a_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/geysir/26320755536_7c769b6218_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/geysir/3542389801_a2cbfee1e1_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/geysir/4748115806_7219c2b3be_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/ireland/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/ireland/15570753471_74db396d14_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/lakes/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/lakes/39933489595_f0e5d85b6d_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/meadow/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/meadow/18864473291_844325caab_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/mongolia/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/mongolia/6076373946_e9ea2aee32_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/newzealand_np/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/newzealand_np/7942812194_9348729b93_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/norway/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/norway/20099378793_cc2df820af_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/norway/25735082181_999927fe5a_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/swiss_landscape/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/swiss_landscape/4079319632_0133685b2c_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/swiss_mountains/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/swiss_mountains/33509672006_bf4c416afd_b.png  \n",
      "   creating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/volcano/\n",
      "  inflating: VPD++/VPD/tamingtransformers/data/sflckr_segmentations/volcano/50254383883_27ed6ea93a_b.png  \n",
      "  inflating: VPD++/VPD/tamingtransformers/data/subreddits.txt  \n",
      "  inflating: VPD++/VPD/tamingtransformers/environment.yaml  \n",
      "  inflating: VPD++/VPD/tamingtransformers/License.txt  \n",
      "  inflating: VPD++/VPD/tamingtransformers/main.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/README.md  \n",
      "   creating: VPD++/VPD/tamingtransformers/scripts/\n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/extract_depth.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/extract_segmentation.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/extract_submodel.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/make_samples.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/make_scene_samples.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/reconstruction_usage.ipynb  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/sample_conditional.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/sample_fast.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/scripts/taming-transformers.ipynb  \n",
      "  inflating: VPD++/VPD/tamingtransformers/setup.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/\n",
      "   creating: VPD++/VPD/tamingtransformers/taming/data/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/ade20k.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/annotated_objects_coco.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/annotated_objects_dataset.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/annotated_objects_open_images.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/base.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/coco.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/data/conditional_builder/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/conditional_builder/objects_bbox.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/conditional_builder/objects_center_points.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/conditional_builder/utils.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/custom.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/faceshq.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/helper_types.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/image_transforms.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/imagenet.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/open_images_helper.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/sflckr.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/data/utils.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/lr_scheduler.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/models/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/models/cond_transformer.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/models/dummy_cond_stage.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/models/vqgan.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/\n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/diffusionmodules/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/diffusionmodules/model.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/discriminator/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/discriminator/model.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/losses/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/losses/__init__.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/losses/lpips.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/losses/segmentation.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/losses/vqperceptual.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/misc/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/misc/coord.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/transformer/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/transformer/mingpt.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/transformer/permuter.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/util.py  \n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/vqvae/\n",
      "   creating: VPD++/VPD/tamingtransformers/taming/modules/vqvae/__pycache__/\n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/vqvae/__pycache__/quantize.cpython-310.pyc  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/modules/vqvae/quantize.py  \n",
      "  inflating: VPD++/VPD/tamingtransformers/taming/util.py  \n",
      "   creating: VPD++/VPD/vpd/\n",
      " extracting: VPD++/VPD/vpd/__init__.py  \n",
      "  inflating: VPD++/VPD/vpd/models.py  \n"
     ]
    }
   ],
   "source": [
    "!unzip VPD2.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1603829d-64c7-457e-899f-05f33318d66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mv VPD++/VPD VPD2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a513304-6bcb-415f-9aa9-6f6060c06ac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'VPD2/refer'\n",
      "/home/jupyter/VPD2/refer\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (3.13.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.66.1)\n",
      "Collecting timm (from -r requirements.txt (line 4))\n",
      "  Downloading timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy (from -r requirements.txt (line 5))\n",
      "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting regex (from -r requirements.txt (line 6))\n",
      "  Downloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.11.3)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (0.22.0)\n",
      "Collecting pycocotools==2.0.2 (from -r requirements.txt (line 9))\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tokenizers (from -r requirements.txt (line 10))\n",
      "  Downloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting h5py (from -r requirements.txt (line 11))\n",
      "  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.2->-r requirements.txt (line 9)) (68.2.2)\n",
      "Collecting cython>=0.27.3 (from pycocotools==2.0.2->-r requirements.txt (line 9))\n",
      "  Using cached Cython-3.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools==2.0.2->-r requirements.txt (line 9)) (3.7.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 1)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Collecting torch>=1.7 (from timm->-r requirements.txt (line 4))\n",
      "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision (from timm->-r requirements.txt (line 4))\n",
      "  Downloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm->-r requirements.txt (line 4)) (6.0.1)\n",
      "Collecting huggingface-hub (from timm->-r requirements.txt (line 4))\n",
      "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting safetensors (from timm->-r requirements.txt (line 4))\n",
      "  Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->-r requirements.txt (line 5))\n",
      "  Downloading wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->-r requirements.txt (line 7)) (1.25.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (10.0.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (2.32.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (2023.9.26)\n",
      "Requirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image->-r requirements.txt (line 8)) (0.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm->-r requirements.txt (line 4)) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm->-r requirements.txt (line 4)) (4.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (2.8.2)\n",
      "Collecting sympy (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm->-r requirements.txt (line 4)) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools==2.0.2->-r requirements.txt (line 9)) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm->-r requirements.txt (line 4)) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.7->timm->-r requirements.txt (line 4))\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m774.0/774.0 kB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m131.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached Cython-3.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Downloading safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m140.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m>\u001b[0m \u001b[31m[45 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /var/tmp/pip-install-326gvzyu/pycocotools_1db7a1f221cc40c3a393a01ad128ccc4/setup.py:12: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.Distribution().fetch_build_eggs(setup_requires)\n",
      "  \u001b[31m   \u001b[0m /opt/conda/lib/python3.10/site-packages/setuptools/__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Requirements should be satisfied by a PEP 517 installer.\n",
      "  \u001b[31m   \u001b[0m         If you are using pip, you can try `pip install --use-pep517`.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist.fetch_build_eggs(dist.setup_requires)\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/coco.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/cocoeval.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/mask.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m copying pycocotools/__init__.py -> build/lib.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m Compiling pycocotools/_mask.pyx because it changed.\n",
      "  \u001b[31m   \u001b[0m [1/1] Cythonizing pycocotools/_mask.pyx\n",
      "  \u001b[31m   \u001b[0m /var/tmp/pip-install-326gvzyu/pycocotools_1db7a1f221cc40c3a393a01ad128ccc4/.eggs/Cython-3.0.7-py3.10-linux-x86_64.egg/Cython/Compiler/Main.py:381: FutureWarning: Cython directive 'language_level' not set, using '3str' for now (Py3). This has changed from earlier releases! File: /var/tmp/pip-install-326gvzyu/pycocotools_1db7a1f221cc40c3a393a01ad128ccc4/pycocotools/_mask.pyx\n",
      "  \u001b[31m   \u001b[0m   tree = Parsing.p_module(s, pxd, full_module_name)\n",
      "  \u001b[31m   \u001b[0m building 'pycocotools._mask' extension\n",
      "  \u001b[31m   \u001b[0m creating build/common\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/common\n",
      "  \u001b[31m   \u001b[0m creating build/temp.linux-x86_64-cpython-310/pycocotools\n",
      "  \u001b[31m   \u001b[0m gcc -pthread -B /opt/conda/compiler_compat -Wno-unused-result -Wsign-compare -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -I/opt/conda/lib/python3.10/site-packages/numpy/core/include -I./common -I/opt/conda/include/python3.10 -c ../common/maskApi.c -o build/temp.linux-x86_64-cpython-310/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
      "  \u001b[31m   \u001b[0m gcc: error: ../common/maskApi.c: No such file or directory\n",
      "  \u001b[31m   \u001b[0m gcc: fatal error: no input files\n",
      "  \u001b[31m   \u001b[0m compilation terminated.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/gcc' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pycocotools\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for pycocotools\n",
      "Failed to build pycocotools\n",
      "\u001b[31mERROR: Could not build wheels for pycocotools, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%cd VPD2/refer\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cde226a-796e-47dc-ab7a-da15c7abb806",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/VPD2/refer'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9724eec-167b-4218-91ee-600995ad2eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "#%cd VPD2/stablediffusion\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e741e2dc-d4ae-4e3e-b1e6-0e7d0436932e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/VPD2/stablediffusion\n",
      "Collecting taming-transformers (from -r requirements.txt (line 20))\n",
      "  Cloning https://github.com/CompVis/taming-transformers.git (to revision master) to /var/tmp/pip-install-1so3n79f/taming-transformers_9addfe54c9e84af1a049b39d0f2b6502\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/CompVis/taming-transformers.git /var/tmp/pip-install-1so3n79f/taming-transformers_9addfe54c9e84af1a049b39d0f2b6502\n",
      "  Resolved https://github.com/CompVis/taming-transformers.git to commit 3ba01b241669f5ade541ce990f7650a3b8f65318\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting clip (from -r requirements.txt (line 21))\n",
      "  Cloning https://github.com/openai/CLIP.git (to revision main) to /var/tmp/pip-install-1so3n79f/clip_b391a0d4f5c0444cb3e3e79b61d6b991\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /var/tmp/pip-install-1so3n79f/clip_b391a0d4f5c0444cb3e3e79b61d6b991\n",
      "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting torchvision==0.12.0 (from -r requirements.txt (line 3))\n",
      "  Downloading torchvision-0.12.0-cp310-cp310-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting albumentations==0.4.3 (from -r requirements.txt (line 4))\n",
      "  Downloading albumentations-0.4.3.tar.gz (3.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting diffusers (from -r requirements.txt (line 5))\n",
      "  Downloading diffusers-0.25.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pudb==2019.2 (from -r requirements.txt (line 6))\n",
      "  Downloading pudb-2019.2.tar.gz (59 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting invisible-watermark (from -r requirements.txt (line 7))\n",
      "  Downloading invisible_watermark-0.2.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting imageio==2.9.0 (from -r requirements.txt (line 8))\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting imageio-ffmpeg==0.4.2 (from -r requirements.txt (line 9))\n",
      "  Downloading imageio_ffmpeg-0.4.2-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-lightning==1.4.2 (from -r requirements.txt (line 10))\n",
      "  Downloading pytorch_lightning-1.4.2-py3-none-any.whl (916 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m916.6/916.6 kB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf==2.1.1 (from -r requirements.txt (line 11))\n",
      "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting test-tube>=0.7.5 (from -r requirements.txt (line 12))\n",
      "  Downloading test_tube-0.7.5.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting streamlit>=0.73.1 (from -r requirements.txt (line 13))\n",
      "  Downloading streamlit-1.29.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting einops==0.3.0 (from -r requirements.txt (line 14))\n",
      "  Downloading einops-0.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting torch-fidelity==0.3.0 (from -r requirements.txt (line 15))\n",
      "  Downloading torch_fidelity-0.3.0-py3-none-any.whl (37 kB)\n",
      "Collecting transformers==4.19.2 (from -r requirements.txt (line 16))\n",
      "  Downloading transformers-4.19.2-py3-none-any.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m127.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchmetrics==0.6.0 (from -r requirements.txt (line 17))\n",
      "  Downloading torchmetrics-0.6.0-py3-none-any.whl (329 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m329.4/329.4 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kornia==0.6 (from -r requirements.txt (line 18))\n",
      "  Downloading kornia-0.6.0-py2.py3-none-any.whl (367 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m367.1/367.1 kB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python==4.8.1.78 (from -r requirements.txt (line 19))\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 22)) (1.25.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0->-r requirements.txt (line 3)) (4.8.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0->-r requirements.txt (line 3)) (2.31.0)\n",
      "Collecting torch==1.11.0 (from torchvision==0.12.0->-r requirements.txt (line 3))\n",
      "  Downloading torch-1.11.0-cp310-cp310-manylinux1_x86_64.whl (750.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.12.0->-r requirements.txt (line 3)) (10.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.3->-r requirements.txt (line 4)) (1.11.3)\n",
      "Collecting imgaug<0.2.7,>=0.2.5 (from albumentations==0.4.3->-r requirements.txt (line 4))\n",
      "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m631.4/631.4 kB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from albumentations==0.4.3->-r requirements.txt (line 4)) (6.0.1)\n",
      "Collecting opencv-python-headless>=4.1.1 (from albumentations==0.4.3->-r requirements.txt (line 4))\n",
      "  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting urwid>=1.1.1 (from pudb==2019.2->-r requirements.txt (line 6))\n",
      "  Downloading urwid-2.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pygments>=1.0 in /opt/conda/lib/python3.10/site-packages (from pudb==2019.2->-r requirements.txt (line 6)) (2.16.1)\n",
      "Collecting future>=0.17.1 (from pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (4.66.1)\n",
      "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (2023.10.0)\n",
      "Collecting tensorboard>=2.2.0 (from pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyDeprecate==0.3.1 (from pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (23.2)\n",
      "Collecting antlr4-python3-runtime==4.8 (from omegaconf==2.1.1->-r requirements.txt (line 11))\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.19.2->-r requirements.txt (line 16)) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.19.2->-r requirements.txt (line 16))\n",
      "  Using cached huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.19.2->-r requirements.txt (line 16))\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.19.2->-r requirements.txt (line 16))\n",
      "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m141.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.10/site-packages (from diffusers->-r requirements.txt (line 5)) (6.8.0)\n",
      "Collecting safetensors>=0.3.1 (from diffusers->-r requirements.txt (line 5))\n",
      "  Using cached safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from invisible-watermark->-r requirements.txt (line 7)) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from test-tube>=0.7.5->-r requirements.txt (line 12)) (2.0.3)\n",
      "Collecting altair<6,>=4.0 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading altair-5.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading blinker-1.7.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (8.1.7)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (14.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (2.8.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (13.6.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (8.2.3)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading validators-0.22.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (3.1.40)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit>=0.73.1->-r requirements.txt (line 13)) (6.3.3)\n",
      "Collecting watchdog>=2.1.5 (from streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m255.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ftfy (from clip->-r requirements.txt (line 21))\n",
      "  Using cached ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (4.19.2)\n",
      "Collecting toolz (from altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13))\n",
      "  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m148.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (3.8.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r requirements.txt (line 13)) (4.0.11)\n",
      "Requirement already satisfied: scikit-image>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4)) (0.22.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4)) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata->diffusers->-r requirements.txt (line 5)) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.20.3->test-tube>=0.7.5->-r requirements.txt (line 12)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=0.20.3->test-tube>=0.7.5->-r requirements.txt (line 12)) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 3)) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.12.0->-r requirements.txt (line 3)) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (3.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.59.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.1.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading Markdown-3.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (68.2.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10))\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip->-r requirements.txt (line 21))\n",
      "  Using cached wcwidth-0.2.12-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit>=0.73.1->-r requirements.txt (line 13)) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (0.12.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit>=0.73.1->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4)) (3.2.1)\n",
      "INFO: pip is looking at multiple versions of scikit-image to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting scikit-image>=0.11.0 (from imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4))\n",
      "  Downloading scikit_image-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4)) (2023.9.26)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.11.0->imgaug<0.2.7,>=0.2.5->albumentations==0.4.3->-r requirements.txt (line 4)) (0.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.4.2->-r requirements.txt (line 10)) (3.2.2)\n",
      "Downloading opencv_python-4.8.1.78-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m61.7/61.7 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.25.0-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m144.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading altair-5.2.0-py3-none-any.whl (996 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m996.9/996.9 kB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
      "Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached safetensors-0.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m127.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading urwid-2.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m293.0/293.0 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
      "Using cached ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
      "Downloading Markdown-3.5.1-py3-none-any.whl (102 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m131.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached wcwidth-0.2.12-py2.py3-none-any.whl (34 kB)\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: albumentations, pudb, antlr4-python3-runtime, test-tube, taming-transformers, clip, future, imgaug\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for albumentations: filename=albumentations-0.4.3-py3-none-any.whl size=60763 sha256=5955c57ba83b2208306bf2d1c4ce5a8f454225704f882f50441d645b123e24ff\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/6d/15/9a/e9e1ded8efc6c809dc42e97dfc5bb4f57267dc02f6a4617f0e\n",
      "  Building wheel for pudb (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pudb: filename=pudb-2019.2-py3-none-any.whl size=63214 sha256=1f02ee48fa1f8f589087584dd293980d0030386ba8b8b63414de5ab01824ca6e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/02/0f/24/1ca86e678056ad3c72b3fe94f829b9bdf92bb4d661c32bbed1\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=e80a244642fb5c3ff1c0a3bc5de8f782ad9ebdf1f599e3dd0483247c2379aa83\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
      "  Building wheel for test-tube (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for test-tube: filename=test_tube-0.7.5-py3-none-any.whl size=25327 sha256=00f3c10fc077516318a7216b61a00427845bd646056decbfa06fdb10e4587e68\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/28/d4/8b/1aeb47c0dedd931b8e6aec55a8091864a69ac6f0adc5b12ea9\n",
      "  Building wheel for taming-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for taming-transformers: filename=taming_transformers-0.0.1-py3-none-any.whl size=1117 sha256=77c4d032b82af70bb910e0955fd61373a29a5c673010d807727b37d935bbfe92\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-uzavx3t7/wheels/12/09/b8/9428139e2e6d798056371e0de0df5157d521c37c949fc6e6ce\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369500 sha256=2aa743ca0b2ce8659b519d12db912e9701b7c20a1994712229ad55ba5fc37606\n",
      "  Stored in directory: /var/tmp/pip-ephem-wheel-cache-uzavx3t7/wheels/33/5b/36/f26cf631f47cd32851aad6ae71f8a17b64a03fbcb442bdbf06\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492024 sha256=589fa75d57742b1950923c180055f8372fe84304253ac2a15c0d17a7419e84fe\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/a9/47/f118e66afd12240e4662752cc22cefae5d97275623aa8ef57d\n",
      "  Building wheel for imgaug (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654002 sha256=3a6a38f176c95d0477832d9fd9c2037cdd87f2beea70d3a6d8971621470cc4df\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/cb/c7/a6/2d7a113c4885dc0f4eacd8f41095763181c0b9a18223ac7533\n",
      "Successfully built albumentations pudb antlr4-python3-runtime test-tube taming-transformers clip future imgaug\n",
      "Installing collected packages: wcwidth, tokenizers, einops, antlr4-python3-runtime, werkzeug, watchdog, validators, urwid, tzlocal, torch, toolz, toml, tensorboard-data-server, safetensors, regex, pyDeprecate, opencv-python-headless, opencv-python, omegaconf, markdown, imageio-ffmpeg, imageio, future, ftfy, blinker, torchvision, torchmetrics, taming-transformers, scikit-image, pydeck, pudb, kornia, invisible-watermark, huggingface-hub, transformers, torch-fidelity, imgaug, diffusers, clip, tensorboard, altair, albumentations, test-tube, streamlit, pytorch-lightning\n",
      "  Attempting uninstall: wcwidth\n",
      "    Found existing installation: wcwidth 0.2.9\n",
      "    Uninstalling wcwidth-0.2.9:\n",
      "      Successfully uninstalled wcwidth-0.2.9\n",
      "  Attempting uninstall: imageio\n",
      "    Found existing installation: imageio 2.32.0\n",
      "    Uninstalling imageio-2.32.0:\n",
      "      Successfully uninstalled imageio-2.32.0\n",
      "  Attempting uninstall: scikit-image\n",
      "    Found existing installation: scikit-image 0.22.0\n",
      "    Uninstalling scikit-image-0.22.0:\n",
      "      Successfully uninstalled scikit-image-0.22.0\n",
      "Successfully installed albumentations-0.4.3 altair-5.2.0 antlr4-python3-runtime-4.8 blinker-1.7.0 clip-1.0 diffusers-0.25.0 einops-0.3.0 ftfy-6.1.3 future-0.18.3 huggingface-hub-0.20.1 imageio-2.9.0 imageio-ffmpeg-0.4.2 imgaug-0.2.6 invisible-watermark-0.2.0 kornia-0.6.0 markdown-3.5.1 omegaconf-2.1.1 opencv-python-4.8.1.78 opencv-python-headless-4.9.0.80 pudb-2019.2 pyDeprecate-0.3.1 pydeck-0.8.1b0 pytorch-lightning-1.4.2 regex-2023.12.25 safetensors-0.4.1 scikit-image-0.20.0 streamlit-1.29.0 taming-transformers-0.0.1 tensorboard-2.15.1 tensorboard-data-server-0.7.2 test-tube-0.7.5 tokenizers-0.12.1 toml-0.10.2 toolz-0.12.0 torch-1.11.0 torch-fidelity-0.3.0 torchmetrics-0.6.0 torchvision-0.12.0 transformers-4.19.2 tzlocal-5.2 urwid-2.4.1 validators-0.22.0 watchdog-3.0.0 wcwidth-0.2.12 werkzeug-3.0.1\n"
     ]
    }
   ],
   "source": [
    "%cd VPD2/stablediffusion\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f7ebdf0-da2e-4b5d-a922-1323e30467d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (1.11.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.12.0)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchtext\n",
      "  Downloading torchtext-0.16.2-cp310-cp310-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.8.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==2.1.0 (from torch)\n",
      "  Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.25.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext) (4.66.1)\n",
      "Collecting torchdata==0.7.1 (from torchtext)\n",
      "  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.1->torchtext) (1.26.18)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2023.7.22)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "Using cached torchvision-0.16.2-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "Downloading torchtext-0.16.2-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchdata, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.11.0\n",
      "    Uninstalling torch-1.11.0:\n",
      "      Successfully uninstalled torch-1.11.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.12.0\n",
      "    Uninstalling torchvision-0.12.0:\n",
      "      Successfully uninstalled torchvision-0.12.0\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.1.2 torchdata-0.7.1 torchtext-0.16.2 torchvision-0.16.2 triton-2.1.0\n",
      "Collecting timm\n",
      "  Using cached timm-0.9.12-py3-none-any.whl.metadata (60 kB)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.20.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm) (12.3.101)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.66.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (23.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.25.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "Using cached timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
      "Installing collected packages: timm\n",
      "Successfully installed timm-0.9.12\n",
      "Collecting torchtext==0.6.0\n",
      "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (4.66.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (2.31.0)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (1.25.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from torchtext==0.6.0) (1.16.0)\n",
      "Collecting sentencepiece (from torchtext==0.6.0)\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchtext==0.6.0) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch->torchtext==0.6.0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6.0) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchtext==0.6.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.16.2\n",
      "    Uninstalling torchtext-0.16.2:\n",
      "      Successfully uninstalled torchtext-0.16.2\n",
      "Successfully installed sentencepiece-0.1.99 torchtext-0.6.0\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (0.3.0)\n",
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m102.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: einops\n",
      "  Attempting uninstall: einops\n",
      "    Found existing installation: einops 0.3.0\n",
      "    Uninstalling einops-0.3.0:\n",
      "      Successfully uninstalled einops-0.3.0\n",
      "Successfully installed einops-0.7.0\n",
      "Collecting keras\n",
      "  Downloading keras-3.0.2-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (2.0.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.25.2)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.6.0)\n",
      "Collecting namex (from keras)\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting h5py (from keras)\n",
      "  Using cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Downloading keras-3.0.2-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Installing collected packages: namex, h5py, keras\n",
      "Successfully installed h5py-3.10.0 keras-3.0.2 namex-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchtext --upgrade\n",
    "!pip install timm\n",
    "!pip install torchtext==0.6.0\n",
    "!apt-get install tree\n",
    "!pip install --upgrade einops\n",
    "!pip install --upgrade keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d450eb87-2b92-4f74-a210-8090fbfe3bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "034f58ba-4e55-4755-b85e-83b1ab5dde76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-05 00:14:06--  http://images.cocodataset.org/zips/train2014.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.70.84, 52.216.39.57, 3.5.11.201, ...\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.70.84|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13510573713 (13G) [application/zip]\n",
      "Saving to: VPD2/refer/data/images/mscoco/images/train2014.zip\n",
      "\n",
      "train2014.zip       100%[===================>]  12.58G  35.7MB/s    in 6m 33s  \n",
      "\n",
      "2024-01-05 00:20:40 (32.8 MB/s) - VPD2/refer/data/images/mscoco/images/train2014.zip saved [13510573713/13510573713]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/zips/train2014.zip -P VPD2/refer/data/images/mscoco/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b92a0ac-f543-433b-a229-0181671db81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-04 23:58:34--  https://cloud.tsinghua.edu.cn/f/78c884b131ec4d9d9fe5/?dl=1\n",
      "Resolving cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)... 166.111.6.101, 2402:f000:1:406:166:111:6:101\n",
      "Connecting to cloud.tsinghua.edu.cn (cloud.tsinghua.edu.cn)|166.111.6.101|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cloud.tsinghua.edu.cn/seafhttp/files/f3a6ce74-b9a4-46a1-a876-06884c7155d8/vpd_ris_refcoco.pth [following]\n",
      "--2024-01-04 23:58:36--  https://cloud.tsinghua.edu.cn/seafhttp/files/f3a6ce74-b9a4-46a1-a876-06884c7155d8/vpd_ris_refcoco.pth\n",
      "Reusing existing connection to cloud.tsinghua.edu.cn:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3599894362 (3.4G) [application/octet-stream]\n",
      "Saving to: vpd_ris_refcoco.pth\n",
      "\n",
      "pth                 100%[===================>]   3.35G  9.40MB/s    in 6m 7s   \n",
      "\n",
      "2024-01-05 00:04:43 (9.36 MB/s) - vpd_ris_refcoco.pth saved [3599894362/3599894362]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O vpd_ris_refcoco.pth https://cloud.tsinghua.edu.cn/f/78c884b131ec4d9d9fe5/?dl=1 -P VP2/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20d2b5a4-070f-4079-84e1-8d3e8dd6c894",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34a26588-0eef-4d58-8195-04233943a5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-05 00:05:57--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
      "Resolving huggingface.co (huggingface.co)... 18.155.129.129, 18.155.129.31, 18.155.129.60, ...\n",
      "Connecting to huggingface.co (huggingface.co)|18.155.129.129|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs.huggingface.co/repos/6b/20/6b201da5f0f5c60524535ebb7deac2eef68605655d3bbacfee9cce0087f3b3f5/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1704671935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNDY3MTkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82Yi8yMC82YjIwMWRhNWYwZjVjNjA1MjQ1MzVlYmI3ZGVhYzJlZWY2ODYwNTY1NWQzYmJhY2ZlZTljY2UwMDg3ZjNiM2Y1L2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qqxO3ZQcKpkOzce1-i-1Nxj4UmISD3fW-0cUbuiamNqHwXx31-Yld%7Ehe6DQ0l%7E2BQBSNmh1oPgDjlL7GqT26baM4Tb%7Eb3I2oGGXliowTcakv4iv6wX6FUewrHpsGAz3FjhUkIOo7oyqjfvmrdwJicdgPxdaCk3RByn38vXqoGvzlWEQ0OxWd4SdY-nii7ejXYJxG-9ZYFqhIe0azX5ve5UO%7ERVJ-tl8ApYZQKUODAt74Bi3qODR1W1dMGIJeDh2NigjZL982ScrbJUpH4BAC1D40WGOKdusPz%7E4nkSVaTFFrf4p8%7EI7GMb5yqOBpiWU-yVnfM0fsipQpmwLUJKepFw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
      "--2024-01-05 00:05:57--  https://cdn-lfs.huggingface.co/repos/6b/20/6b201da5f0f5c60524535ebb7deac2eef68605655d3bbacfee9cce0087f3b3f5/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1704671935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNDY3MTkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy82Yi8yMC82YjIwMWRhNWYwZjVjNjA1MjQ1MzVlYmI3ZGVhYzJlZWY2ODYwNTY1NWQzYmJhY2ZlZTljY2UwMDg3ZjNiM2Y1L2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qqxO3ZQcKpkOzce1-i-1Nxj4UmISD3fW-0cUbuiamNqHwXx31-Yld%7Ehe6DQ0l%7E2BQBSNmh1oPgDjlL7GqT26baM4Tb%7Eb3I2oGGXliowTcakv4iv6wX6FUewrHpsGAz3FjhUkIOo7oyqjfvmrdwJicdgPxdaCk3RByn38vXqoGvzlWEQ0OxWd4SdY-nii7ejXYJxG-9ZYFqhIe0azX5ve5UO%7ERVJ-tl8ApYZQKUODAt74Bi3qODR1W1dMGIJeDh2NigjZL982ScrbJUpH4BAC1D40WGOKdusPz%7E4nkSVaTFFrf4p8%7EI7GMb5yqOBpiWU-yVnfM0fsipQpmwLUJKepFw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
      "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 52.222.174.26, 52.222.174.30, 52.222.174.3, ...\n",
      "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|52.222.174.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4265380512 (4.0G) [binary/octet-stream]\n",
      "Saving to: VPD2/checkpoints/v1-5-pruned-emaonly.ckpt\n",
      "\n",
      "v1-5-pruned-emaonly 100%[===================>]   3.97G   449MB/s    in 9.1s    \n",
      "\n",
      "2024-01-05 00:06:06 (448 MB/s) - VPD2/checkpoints/v1-5-pruned-emaonly.ckpt saved [4265380512/4265380512]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -P VPD2/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f2c91e5-99ac-4ff9-93d7-384d0feb9ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24ce8971-0c83-4244-808c-357a2ea86511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q VPD2/refer/data/images/mscoco/images/train2014 -d VPD2/refer/data/images/mscoco/images/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c266c03-e4d8-45a2-8bbf-1b0cff2aad79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ac7799cb-c2b0-4f51-bfc9-d27b72905f44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 512\n",
      "loading dataset refcoco into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=10.96s)\n",
      "loading dataset refcoco into memory...\n",
      "creating index...\n",
      "index created.\n",
      "DONE (t=10.31s)\n",
      "local rank None / global rank 0 successfully built train dataset.\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 859.52 M params.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
      "making attention of type 'vanilla' with 512 in_channels\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'visual_projection.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'logit_scale', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.embeddings.position_ids', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Restored from VPD2/checkpoints/v1-5-pruned-emaonly.ckpt with 0 missing and 2 unexpected keys\n",
      "Unexpected Keys: ['model_ema.decay', 'model_ema.num_updates']\n",
      "Some weights of the model checkpoint at openai/clip-vit-large-patch14 were not used when initializing CLIPTextModel: ['vision_model.encoder.layers.6.self_attn.k_proj.bias', 'vision_model.encoder.layers.20.self_attn.out_proj.weight', 'vision_model.encoder.layers.19.layer_norm1.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.self_attn.q_proj.bias', 'vision_model.encoder.layers.7.self_attn.out_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.bias', 'vision_model.encoder.layers.16.layer_norm1.weight', 'vision_model.encoder.layers.10.mlp.fc1.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.weight', 'vision_model.encoder.layers.23.mlp.fc2.weight', 'vision_model.encoder.layers.10.layer_norm1.bias', 'vision_model.encoder.layers.10.mlp.fc2.weight', 'vision_model.encoder.layers.21.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.weight', 'vision_model.post_layernorm.weight', 'vision_model.encoder.layers.9.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.layer_norm1.weight', 'vision_model.encoder.layers.2.mlp.fc1.bias', 'vision_model.encoder.layers.19.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.weight', 'vision_model.encoder.layers.21.mlp.fc2.weight', 'vision_model.encoder.layers.5.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.bias', 'vision_model.encoder.layers.2.layer_norm1.bias', 'vision_model.encoder.layers.18.layer_norm2.bias', 'vision_model.encoder.layers.23.layer_norm2.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.bias', 'vision_model.encoder.layers.3.mlp.fc1.weight', 'vision_model.encoder.layers.0.mlp.fc2.bias', 'vision_model.encoder.layers.5.mlp.fc2.weight', 'vision_model.encoder.layers.3.layer_norm1.weight', 'vision_model.encoder.layers.7.layer_norm2.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.bias', 'vision_model.encoder.layers.1.mlp.fc2.weight', 'vision_model.encoder.layers.1.mlp.fc2.bias', 'vision_model.encoder.layers.4.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc1.weight', 'vision_model.encoder.layers.10.layer_norm2.weight', 'vision_model.encoder.layers.12.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.k_proj.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.bias', 'vision_model.encoder.layers.9.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.v_proj.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.bias', 'vision_model.encoder.layers.8.self_attn.k_proj.weight', 'vision_model.pre_layrnorm.weight', 'vision_model.encoder.layers.5.mlp.fc2.bias', 'vision_model.encoder.layers.6.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.out_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.bias', 'vision_model.encoder.layers.18.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.layer_norm1.bias', 'vision_model.encoder.layers.10.layer_norm2.bias', 'vision_model.encoder.layers.19.layer_norm2.bias', 'vision_model.encoder.layers.12.layer_norm2.weight', 'vision_model.encoder.layers.20.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.mlp.fc1.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.mlp.fc1.weight', 'vision_model.encoder.layers.4.mlp.fc2.weight', 'vision_model.encoder.layers.6.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.q_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.layer_norm1.bias', 'vision_model.encoder.layers.20.layer_norm2.bias', 'vision_model.encoder.layers.1.layer_norm2.bias', 'vision_model.encoder.layers.5.self_attn.out_proj.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.mlp.fc2.bias', 'vision_model.encoder.layers.21.layer_norm2.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.mlp.fc1.bias', 'vision_model.encoder.layers.20.self_attn.k_proj.bias', 'vision_model.encoder.layers.18.layer_norm2.weight', 'vision_model.encoder.layers.19.self_attn.q_proj.weight', 'vision_model.encoder.layers.12.layer_norm2.bias', 'vision_model.encoder.layers.1.mlp.fc1.weight', 'vision_model.encoder.layers.9.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.weight', 'vision_model.encoder.layers.14.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.layer_norm1.bias', 'vision_model.encoder.layers.6.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.bias', 'vision_model.encoder.layers.23.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.layer_norm2.bias', 'vision_model.encoder.layers.3.self_attn.q_proj.weight', 'vision_model.encoder.layers.3.mlp.fc2.bias', 'vision_model.encoder.layers.17.self_attn.q_proj.bias', 'vision_model.encoder.layers.2.self_attn.out_proj.weight', 'vision_model.encoder.layers.14.layer_norm2.bias', 'vision_model.encoder.layers.18.self_attn.k_proj.bias', 'vision_model.encoder.layers.3.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.mlp.fc2.weight', 'vision_model.encoder.layers.23.layer_norm2.weight', 'vision_model.encoder.layers.1.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.bias', 'vision_model.encoder.layers.2.layer_norm2.bias', 'vision_model.encoder.layers.15.mlp.fc1.bias', 'vision_model.encoder.layers.15.layer_norm2.bias', 'vision_model.encoder.layers.8.self_attn.out_proj.weight', 'vision_model.encoder.layers.12.layer_norm1.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.bias', 'vision_model.encoder.layers.6.mlp.fc2.bias', 'vision_model.encoder.layers.6.layer_norm2.bias', 'vision_model.encoder.layers.23.self_attn.out_proj.weight', 'vision_model.encoder.layers.13.layer_norm2.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc1.bias', 'vision_model.encoder.layers.17.mlp.fc1.bias', 'vision_model.encoder.layers.3.layer_norm2.weight', 'vision_model.encoder.layers.10.mlp.fc2.bias', 'vision_model.encoder.layers.4.layer_norm1.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.bias', 'vision_model.encoder.layers.10.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.k_proj.weight', 'vision_model.encoder.layers.10.mlp.fc1.weight', 'vision_model.encoder.layers.11.mlp.fc1.weight', 'vision_model.encoder.layers.16.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.layer_norm1.weight', 'vision_model.encoder.layers.18.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.weight', 'vision_model.encoder.layers.11.mlp.fc2.weight', 'vision_model.encoder.layers.18.layer_norm1.weight', 'vision_model.encoder.layers.8.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.q_proj.bias', 'vision_model.encoder.layers.20.mlp.fc2.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.bias', 'vision_model.encoder.layers.7.layer_norm1.weight', 'vision_model.encoder.layers.13.layer_norm1.weight', 'vision_model.encoder.layers.3.mlp.fc1.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.mlp.fc1.bias', 'vision_model.encoder.layers.23.mlp.fc1.bias', 'vision_model.encoder.layers.6.mlp.fc2.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.q_proj.weight', 'vision_model.encoder.layers.19.mlp.fc2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.weight', 'vision_model.encoder.layers.11.layer_norm1.bias', 'vision_model.encoder.layers.2.self_attn.q_proj.weight', 'vision_model.encoder.layers.8.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.mlp.fc1.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.bias', 'vision_model.encoder.layers.14.mlp.fc1.bias', 'vision_model.encoder.layers.0.layer_norm1.bias', 'vision_model.encoder.layers.13.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.layer_norm2.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.bias', 'vision_model.encoder.layers.21.self_attn.k_proj.bias', 'vision_model.encoder.layers.19.self_attn.k_proj.weight', 'vision_model.encoder.layers.4.layer_norm2.bias', 'visual_projection.weight', 'vision_model.encoder.layers.13.layer_norm2.bias', 'vision_model.encoder.layers.8.layer_norm2.weight', 'vision_model.encoder.layers.3.self_attn.out_proj.weight', 'vision_model.embeddings.position_embedding.weight', 'vision_model.encoder.layers.0.layer_norm2.weight', 'vision_model.encoder.layers.10.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.bias', 'vision_model.encoder.layers.20.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.bias', 'vision_model.encoder.layers.11.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.weight', 'logit_scale', 'vision_model.encoder.layers.13.mlp.fc2.bias', 'vision_model.encoder.layers.8.layer_norm1.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.weight', 'vision_model.encoder.layers.3.layer_norm1.bias', 'vision_model.encoder.layers.21.self_attn.v_proj.weight', 'vision_model.encoder.layers.4.mlp.fc2.bias', 'vision_model.encoder.layers.14.mlp.fc2.bias', 'vision_model.encoder.layers.18.layer_norm1.bias', 'vision_model.encoder.layers.2.layer_norm2.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.weight', 'text_projection.weight', 'vision_model.encoder.layers.22.self_attn.v_proj.bias', 'vision_model.encoder.layers.19.layer_norm1.bias', 'vision_model.encoder.layers.15.layer_norm1.bias', 'vision_model.encoder.layers.5.mlp.fc1.weight', 'vision_model.encoder.layers.17.self_attn.k_proj.weight', 'vision_model.encoder.layers.2.self_attn.v_proj.weight', 'vision_model.encoder.layers.6.layer_norm2.weight', 'vision_model.encoder.layers.21.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.layer_norm2.bias', 'vision_model.encoder.layers.16.layer_norm1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.bias', 'vision_model.encoder.layers.9.layer_norm2.weight', 'vision_model.encoder.layers.12.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc2.weight', 'vision_model.encoder.layers.0.self_attn.v_proj.weight', 'vision_model.encoder.layers.23.layer_norm1.weight', 'vision_model.encoder.layers.20.self_attn.out_proj.bias', 'vision_model.encoder.layers.6.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.layer_norm2.weight', 'vision_model.encoder.layers.16.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.bias', 'vision_model.encoder.layers.22.layer_norm1.weight', 'vision_model.encoder.layers.23.self_attn.k_proj.bias', 'vision_model.encoder.layers.14.self_attn.v_proj.weight', 'vision_model.encoder.layers.20.layer_norm2.weight', 'vision_model.encoder.layers.7.mlp.fc1.weight', 'vision_model.encoder.layers.15.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc1.weight', 'vision_model.encoder.layers.7.self_attn.out_proj.bias', 'vision_model.encoder.layers.11.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.bias', 'vision_model.encoder.layers.22.layer_norm1.bias', 'vision_model.encoder.layers.9.self_attn.q_proj.weight', 'vision_model.encoder.layers.23.self_attn.out_proj.bias', 'vision_model.encoder.layers.3.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.bias', 'vision_model.encoder.layers.22.self_attn.v_proj.weight', 'vision_model.encoder.layers.21.self_attn.out_proj.bias', 'vision_model.embeddings.class_embedding', 'vision_model.encoder.layers.21.mlp.fc1.bias', 'vision_model.encoder.layers.5.layer_norm1.bias', 'vision_model.encoder.layers.1.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.q_proj.weight', 'vision_model.encoder.layers.6.layer_norm1.weight', 'vision_model.encoder.layers.3.self_attn.q_proj.bias', 'vision_model.encoder.layers.5.self_attn.v_proj.weight', 'vision_model.encoder.layers.10.self_attn.k_proj.bias', 'vision_model.encoder.layers.23.self_attn.k_proj.weight', 'vision_model.encoder.layers.20.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.self_attn.k_proj.bias', 'vision_model.encoder.layers.0.mlp.fc2.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.bias', 'vision_model.encoder.layers.4.layer_norm2.weight', 'vision_model.encoder.layers.9.self_attn.k_proj.weight', 'vision_model.encoder.layers.15.self_attn.q_proj.bias', 'vision_model.encoder.layers.23.self_attn.q_proj.bias', 'vision_model.encoder.layers.18.self_attn.v_proj.weight', 'vision_model.encoder.layers.7.mlp.fc1.bias', 'vision_model.encoder.layers.22.self_attn.q_proj.weight', 'vision_model.encoder.layers.11.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.out_proj.weight', 'vision_model.embeddings.patch_embedding.weight', 'vision_model.encoder.layers.13.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.v_proj.bias', 'vision_model.encoder.layers.3.self_attn.k_proj.bias', 'vision_model.encoder.layers.16.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.k_proj.weight', 'vision_model.encoder.layers.18.mlp.fc2.weight', 'vision_model.encoder.layers.12.mlp.fc2.bias', 'vision_model.encoder.layers.16.layer_norm2.bias', 'vision_model.encoder.layers.2.layer_norm1.weight', 'vision_model.encoder.layers.21.self_attn.k_proj.weight', 'vision_model.encoder.layers.8.layer_norm2.bias', 'vision_model.encoder.layers.11.layer_norm1.weight', 'vision_model.encoder.layers.14.self_attn.k_proj.bias', 'vision_model.encoder.layers.8.mlp.fc2.bias', 'vision_model.encoder.layers.19.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.mlp.fc1.bias', 'vision_model.encoder.layers.9.mlp.fc1.bias', 'vision_model.encoder.layers.0.self_attn.k_proj.bias', 'vision_model.encoder.layers.5.layer_norm1.weight', 'vision_model.encoder.layers.19.self_attn.v_proj.bias', 'vision_model.encoder.layers.12.self_attn.k_proj.weight', 'vision_model.encoder.layers.0.layer_norm2.bias', 'vision_model.encoder.layers.13.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.mlp.fc2.weight', 'vision_model.encoder.layers.16.layer_norm2.weight', 'vision_model.encoder.layers.0.self_attn.out_proj.bias', 'vision_model.encoder.layers.17.layer_norm1.weight', 'vision_model.encoder.layers.19.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc1.weight', 'vision_model.encoder.layers.10.self_attn.q_proj.weight', 'vision_model.encoder.layers.13.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.layer_norm2.weight', 'vision_model.encoder.layers.18.mlp.fc2.bias', 'vision_model.encoder.layers.22.self_attn.k_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.mlp.fc1.weight', 'vision_model.encoder.layers.4.self_attn.v_proj.weight', 'vision_model.encoder.layers.17.self_attn.out_proj.weight', 'vision_model.encoder.layers.5.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.layer_norm1.weight', 'vision_model.encoder.layers.11.self_attn.out_proj.weight', 'vision_model.encoder.layers.22.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.bias', 'vision_model.encoder.layers.3.mlp.fc2.weight', 'vision_model.encoder.layers.23.self_attn.v_proj.weight', 'vision_model.encoder.layers.22.layer_norm2.weight', 'vision_model.encoder.layers.5.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.weight', 'vision_model.encoder.layers.6.self_attn.out_proj.bias', 'vision_model.encoder.layers.21.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.mlp.fc1.weight', 'vision_model.encoder.layers.9.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.bias', 'vision_model.encoder.layers.1.layer_norm2.weight', 'vision_model.encoder.layers.4.self_attn.k_proj.weight', 'vision_model.encoder.layers.12.self_attn.q_proj.bias', 'vision_model.encoder.layers.17.self_attn.k_proj.bias', 'vision_model.encoder.layers.13.mlp.fc1.weight', 'vision_model.encoder.layers.1.self_attn.out_proj.weight', 'vision_model.encoder.layers.2.self_attn.k_proj.weight', 'vision_model.encoder.layers.5.self_attn.k_proj.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.bias', 'vision_model.encoder.layers.14.layer_norm1.weight', 'vision_model.encoder.layers.22.layer_norm2.bias', 'vision_model.encoder.layers.9.layer_norm2.bias', 'vision_model.embeddings.position_ids', 'vision_model.pre_layrnorm.bias', 'vision_model.encoder.layers.4.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.out_proj.weight', 'vision_model.encoder.layers.20.self_attn.q_proj.bias', 'vision_model.encoder.layers.8.self_attn.q_proj.bias', 'vision_model.encoder.layers.12.mlp.fc2.weight', 'vision_model.encoder.layers.17.layer_norm2.bias', 'vision_model.encoder.layers.1.self_attn.k_proj.bias', 'vision_model.encoder.layers.17.layer_norm2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.bias', 'vision_model.encoder.layers.1.self_attn.v_proj.bias', 'vision_model.encoder.layers.14.self_attn.q_proj.weight', 'vision_model.encoder.layers.4.self_attn.q_proj.bias', 'vision_model.encoder.layers.15.self_attn.v_proj.bias', 'vision_model.encoder.layers.21.mlp.fc2.bias', 'vision_model.encoder.layers.0.layer_norm1.weight', 'vision_model.encoder.layers.15.mlp.fc1.weight', 'vision_model.encoder.layers.6.self_attn.v_proj.bias', 'vision_model.post_layernorm.bias', 'vision_model.encoder.layers.7.self_attn.v_proj.weight', 'vision_model.encoder.layers.13.mlp.fc2.weight', 'vision_model.encoder.layers.7.self_attn.q_proj.weight', 'vision_model.encoder.layers.0.mlp.fc1.bias', 'vision_model.encoder.layers.11.mlp.fc1.bias', 'vision_model.encoder.layers.7.self_attn.k_proj.weight', 'vision_model.encoder.layers.9.layer_norm1.weight', 'vision_model.encoder.layers.1.layer_norm1.weight', 'vision_model.encoder.layers.9.self_attn.v_proj.weight', 'vision_model.encoder.layers.16.self_attn.out_proj.weight', 'vision_model.encoder.layers.15.self_attn.k_proj.weight', 'vision_model.encoder.layers.11.self_attn.v_proj.bias', 'vision_model.encoder.layers.1.self_attn.q_proj.weight', 'vision_model.encoder.layers.7.mlp.fc2.bias', 'vision_model.encoder.layers.16.self_attn.out_proj.bias', 'vision_model.encoder.layers.16.mlp.fc1.bias', 'vision_model.encoder.layers.12.self_attn.v_proj.bias', 'vision_model.encoder.layers.11.layer_norm2.bias', 'vision_model.encoder.layers.0.self_attn.out_proj.weight', 'vision_model.encoder.layers.18.self_attn.out_proj.weight', 'vision_model.encoder.layers.21.layer_norm2.bias', 'vision_model.encoder.layers.20.layer_norm1.weight', 'vision_model.encoder.layers.0.mlp.fc1.weight', 'vision_model.encoder.layers.2.mlp.fc2.bias', 'vision_model.encoder.layers.16.mlp.fc2.weight', 'vision_model.encoder.layers.13.layer_norm1.bias', 'vision_model.encoder.layers.21.layer_norm1.bias', 'vision_model.encoder.layers.17.self_attn.out_proj.bias', 'vision_model.encoder.layers.10.self_attn.out_proj.weight', 'vision_model.encoder.layers.17.self_attn.v_proj.weight', 'vision_model.encoder.layers.19.layer_norm2.weight', 'vision_model.encoder.layers.17.mlp.fc1.weight', 'vision_model.encoder.layers.13.self_attn.q_proj.weight', 'vision_model.encoder.layers.15.mlp.fc2.bias']\n",
      "- This IS expected if you are initializing CLIPTextModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CLIPTextModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Number of parameters to optimize: 39603202\n",
      "Total number of trainable parameters: 899124166\n",
      "256\n",
      "torch.Size([4, 256, 77])\n",
      "256\n",
      "torch.Size([4, 256, 77])\n",
      "256\n",
      "torch.Size([4, 256, 77])\n",
      "1024\n",
      "torch.Size([4, 1024, 77])\n",
      "1024\n",
      "torch.Size([4, 1024, 77])\n",
      "1024\n",
      "torch.Size([4, 1024, 77])\n",
      "1024\n",
      "torch.Size([4, 1024, 77])\n",
      "1024\n",
      "torch.Size([4, 1024, 77])\n",
      "256\n",
      "torch.Size([4, 256, 77])\n",
      "256\n",
      "torch.Size([4, 256, 77])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/VPD2/refer/my_train.py\", line 323, in <module>\n",
      "    main(args)\n",
      "  File \"/home/jupyter/VPD2/refer/my_train.py\", line 293, in main\n",
      "    train_one_epoch(model, criterion, optimizer, data_loader, lr_scheduler, epoch, args.print_freq,\n",
      "  File \"/home/jupyter/VPD2/refer/my_train.py\", line 149, in train_one_epoch\n",
      "    loss.backward()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py\", line 288, in apply\n",
      "    return user_fn(self, *args)\n",
      "  File \"/home/jupyter/VPD2/stablediffusion/ldm/modules/diffusionmodules/util.py\", line 139, in backward\n",
      "    input_grads = torch.autograd.grad(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 394, in grad\n",
      "    result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 2.00 GiB. GPU 0 has a total capacty of 15.89 GiB of which 727.88 MiB is free. Including non-PyTorch memory, this process has 15.18 GiB memory in use. Of the allocated memory 12.73 GiB is allocated by PyTorch, and 1.45 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!python VPD2/refer/my_train.py --dataset refcoco --split val --epochs 1 --batch-size 4 --workers 4 --img_size 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d9a9c44f-5ff6-4478-8831-5da11c2c4813",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:04.0 3D controller: NVIDIA Corporation GP100GL [Tesla P100 PCIe 16GB] (rev a1)\n"
     ]
    }
   ],
   "source": [
    "!lspci | grep -i nvidia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7a01fd0-78c8-4863-93a2-3a6103bd4c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch==2.1.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (2325.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m583.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting torchvision==0.16.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.16.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==2.1.1\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.1.1%2Bcu118-cp310-cp310-linux_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (4.8.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (2023.10.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.1.1) (2.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.1) (1.25.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.1) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.16.1) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.1.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.16.1) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.1) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.16.2\n",
      "    Uninstalling torchvision-0.16.2:\n",
      "      Successfully uninstalled torchvision-0.16.2\n",
      "Successfully installed torch-2.1.1+cu118 torchaudio-2.1.1+cu118 torchvision-0.16.1+cu118\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.1.1 torchvision==0.16.1 torchaudio==2.1.1 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa64d8cd-3abd-4900-8c3d-5cbb5261747f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ee1b075-5a79-473d-9d80-da9594839cfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1-5-pruned-emaonly.ckpt\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d03c2e6c-0f05-4fc6-9aa1-22332bc282c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in /opt/conda/lib/python3.10/site-packages (2.0.7)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools) (3.7.3)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools) (1.25.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b35c0f84-cc2d-4ac8-b97c-3ea960fabc5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "47c3609d-fc44-4e45-b050-956529457577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/VPD2/refer/data/images/mscoco/images/train2014\n"
     ]
    }
   ],
   "source": [
    "%cd VPD2/refer/data/images/mscoco/images/train2014/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c53dd-5104-4376-aa0e-d04bfe0298b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "rm *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d0f0eeb8-3f6c-48d8-b47b-87a7200ab169",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2e30dfcd-9c98-4189-bfd9-c7feca68e6b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -r VPD2/checkpoints/*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8829d802-03d2-4a32-ad4a-b2f46e3ecebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rm\n",
      "  Downloading rm-2020.12.3.tar.gz (1.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting values (from rm)\n",
      "  Downloading values-2020.12.3.tar.gz (1.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: rm, values\n",
      "  Building wheel for rm (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rm: filename=rm-2020.12.3-py3-none-any.whl size=1363 sha256=9d58e0ffdec3968f2be26cab0ebe90284c1dac66189e2fe987ec20bd15de0d9c\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5e/e0/78/cf1c7b0b05c261b202608c9a3ef2ef510dbcc9cf14d7785583\n",
      "  Building wheel for values (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for values: filename=values-2020.12.3-py3-none-any.whl size=1339 sha256=59fc350e6c48812fda1e85d9f310e5195145a3d4360d91dbaf404affed8a99b2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/a7/bc/50/73bf2f3bc5ea44e3a0ca1ce38c2fa0d05967ef3ff5d5698978\n",
      "Successfully built rm values\n",
      "Installing collected packages: values, rm\n",
      "Successfully installed rm-2020.12.3 values-2020.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d0b827-dde0-4f51-a4a9-57918bb15069",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip -rq VPD2.zip VPD2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb5b677-1fc5-4634-90b6-e4ce9dd419b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
